---
layout: about
title: about
permalink: /
subtitle: M.S Student, Yonsei University

profile:
  align: right
  image: self.png
  image_circular: false # crops the image to make it circular
  more_info: >
    <p> seungblee@yonsei.ac.kr</p>

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page
---
<a href="mailto:seungblee@yonsei.ac.kr">[E-mail]</a> <a href="https://github.com/seunbite">[Github]</a> <a href="https://scholar.google.com/citations?user=YdbC5yUAAAAJ&hl=ko">[Google Scholar]</a> <a href="/assets/cv/Seungbeen-CV.pdf" download>[CV]</a>


Hello, I’m Seungbeen Lee, currently in my master’s degree at Yonsei University advised by Professor [Youngjae Yu](https://scholar.google.com/citations?user=WDO24ZYAAAAJ&hl=ko&oi=ao). I completed my undergraduate studies in `Psychology` and `Economics` in Yonsei University.  I still love discussing about [Personality Psychology](https://en.wikipedia.org/wiki/Personality_psychology), [Social Psychology](https://www.youtube.com/watch?v=meiU6TxysCg), and [Game Theory](https://www.youtube.com/watch?v=iLX_r_WPrIw). I’ve always been fascinated by modeling human decision-making, and I graduated with the insight that humans are beings most significantly influenced by the presence and decision-making of others.

I’m interested in developing agents that make decisions like humans. Importantly, I’m convinced that ai will be able to `fulfill fundamental social needs of human`. Right now, they’re just slightly incapable, like the language models of the 2010s. I'm interested in these research topics:

#### AI to Meet Social Desires 
I think about why AI can’t be a meaningful friend to humans yet. Friendship requires `high level of detail`. I’m interested in developing agents that go beyond just making rational and safe responses - agents that can make humans laugh, feel joy, feel sadness, be moved, (sometimes) feel lonely, feel supported, view the world rationally, and see it emotionally. This will require highly sophisticated language abilities, and an easier approach might be an (adorably designed) embodied form. Just typing is not an easy way to make people feel immersed in the interaction.

#### Next State Prediction, Next Behavior Prediction 
I read [a paper](https://life2vecai.com/) and am so interested in predicting life events using probabilistic models. Career prediction is one aspect - career choice is one of the most important ‘probabilistic’ decision-making processes in our lives. Therefore, I believe that with a sophisticated probabilistic model and good data,  we can predict `human behavioral patterns` (Will they bow? Offer a handshake? Ignore?). I’m also interested in collecting and refining resources from various data sources like YouTube for this purpose.

#### Sophisticated Reward Model in AI Brain 
While humans haven’t always evolved to be smarter, they have various reward models built into their brains for efficient survival and reproduction. For example, the human brain is designed to release comparable levels of dopamine when receiving social recognition compared to material recognition ([ref](https://pubmed.ncbi.nlm.nih.gov/18439412/)). Most human brains weren’t designed to become smarter, and the conclusion from this long evolution is the importance of `‘sociability'`. This doesn’t mean IQ of 200. An IQ of around 90 is sufficient if one can read others’ emotional changes well and understand their needs - that’s enough to live well together. I’m interested in creating such sophisticated reward models for AI.